# Docker

Docker - это программноее обеспечение для автоматизации развертывания и управления приложениями в средах с поддержкой контейнеризации.

## Контейнеризация и виртуализация

### Виртуализация

В начале 2000-х годов большинство приложений были монолитными. У каждого приложения была куча зависимостей. При этом самих инстансов сереров было не очень много но они были достаточно мощными. Для организации ресурсов использовалась __виртуализация__: один "жирный" сервер пилился на несколько виртуалок и тем самым мы получали изоляцию окружений.

Системы виртуализации:

* vmware
* Oracle VirtualBox
* Microsoft Hyper-V
* EMU

Системы виртуализации справляются со своими задачами изоляции окружения и ресурс менеджмента, но имеют ряд недостатков:

* для работы виртуальных машин необходим __гипервизор__. Гипервизор накладывает оверхед, так как сам потребляет ресурсы;
* виртуалка представляет собой массивный образ, в котором стоит полноценная ОС и все необходимые программы. В результате, работа с такой виртуалкой может быть медленной и неудобной.

### Виртуализация на уровне ядра

Чтобы решить проблемы виртуализации появилась виртуализация на уровне ядра. Это такие системы как

* OpenVZ
* System-nspawn
* LXC (Linux Containers)

В системах с виртуализацией на уровне ядра отсутствует гипервизор. Вместо него есть контейнерный движок (container engine). Он гораздо более легковесный по сравнению с гипервизором и за счет работы с ядром ОС хост-машины оверхед гораздо меньше или отсутствует совсем.

Разница виртуалиной машины и контейнера: виртуальная машина подразумевает виртуализацию железа для запуска гостевой ОС, в то время как контейнер использует ядро хостовой системы. Как следствие, в виртуалке может работать любая ОС, а в контейнере может работать только Linux (недавно и Windows). Виртуальная машина идеально подходит, если необходимо изолировать окружение, а контейнер для изоляции - это плохо, так как в системах с изоляцией на уровне ядра ОС часто находят уязвимости, которые позволяют из контейнера выбраться на хост-машину.

Для контейнеризации на уровне ядра существует несколько основых технологий:

1. Namespaces
   * PID - позволяет изолировать процесс от других процессов. Процесс, помещенный в PID namespace имеет PID = 1. В обычных системах процесс с PID = 1 это Systemd или init.
   * Networking - позволяет изолировать сеть.
   * Mount - позволяет ограничить файловую систему.
   * User - ограничения по юзерам.
   * ...
2. Control Groups. Они управляют ресурсами для контейнера. С их помощью можно сказать, что определенный контейнер не должен потреблять ресурсов больше указанных.
   * Memory - ограничения по памяти
   * CPU - ограничения по CPU
   * Block I/O - ограничения по iops
   * Network - ограничения по сети
3. Capabilities - возможность сказать процессу, что он может делать, а что не может. Например, пользователь root может делать все, а сервер времени (pd) может изменять системное время, но не может зайти в папку root и изменить права. С помощью capabilities можно очень гибко настроить то, что может делать наш процесс и тем самым обезопасить себя.
4. Copy-on-Write - система, которая позволяет работать с образами Докера.
5. ...

Виртуалиация на уровне ядра позволила устранить оверхед на гипервизор, но проблема с тяжелыми образами осталась. Например в OpenVZ суют ОС, программы, библиотеки  т.д. У этих систем нет нормального стандарта упаковки и доставки. И также остается проблема с зависимостями, например, когда два куска кода используют одну библиотеку, но разных версий.

Для решения этих проблем придумали контейнеризацию.

### Контейнеризация

Контейнеризация - это другая философия работы с контейнерами. Согласно этой философии мы запускаем в одном контейнере только один процесс. Все зависимости, которые нужны этому процессу доставляются в этот контейнер. Чем меньше образ - тем лучше. Монолитные приложения распиливаются на микросервисы и количество инстансов серверов значительно увеличивается. Нам становиться не так важно контролировать каждый конкретный контейнер. Нам скорее важна доступность самого сервиса (то что делает набор контейнеров). Соответственно, такая философия меняет подходы в мониторинге. Именно после появления такой философии получает большую популярность Docker.

Docker стандартизирует упаковку приложения: мы можем упаковать приложение, отправить его в репозиторий, скачать его от туда и развернуть.

Docker решает вопрос зависимостей, потому что в Docker-контейнер мы упаковываем все необходимые зависимости.

Использование Docker гарантирует воспроизводимость. Проблема воспроизводимости - это когда, например у разработчика на локальной машине все работает, а на сервере перестает работать.

Docker сводит к минимуму оверхед (или совсем убирает его - люди спорят об этом).

## Составные части Docker

Docker состоит из нескольких составных частей:

* Docker deamon
* Docker CLI
* Dockerfile
* Image
* Container
* Docker registry

### Docker Deamon

Это среверная часть системы Docker. Он работает на хост машине.

Основные задачи:

* создание образов;
* скачивание готовых образов;
* запуск контейнеров из образов;
* создание сети между контейнерами;
* сбор логов контейнеров;

### Docker CLI

Это консольная утилита для работы с докер-демоном. Может работать как локально по Unix-сокету (на одном хосте с докер демоном), так и по сети (по TCP).

### Dockerfile

Это набор инструкций по тому, как собирать образ.

### Image

Это образ, из которого создается контейнер.

### Контейнер

Это контейнер, который создается из образа.

### Docker registry

Это хранилище образов.

Общая схема взаимодействия такая: docker cli посылает команды демону, например собрать образ, скачать образ, запустить контейнер и т.п. Демон выполняет эти команды. Клиент и демон могут находиться как на одном хосте, так и на разных. В первом случае общение будет осуществляться через Unix сокеты, а во втором случае по протоколу TCP. При необходимость демон ходит в хранилище образов (registry) и скачивает готовые образы оттуда.
